{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c37b687",
   "metadata": {},
   "source": [
    "# How to Use FuriosaAI SDK’s Tool Calling to build AI Agents\n",
    "\n",
    "The latest Llama models, including versions 3.1, 3.2, and 4, include native support for tool calling, making it easy to build agentic systems that request information from a wide range of APIs and then use that information to inform the system’s response to user queries. In this notebook, we'll explore what tool calling means in the context of large language models (LLMs), and demonstrate how to build AI agents running on RNGD (pronounced “Renegade”), Furiosa’s flagship AI accelerator for LLMs, RAG applications, and agentic AI. In this demo, we’ll use the Llama 3.1 8B model in the FuriosaAI SDK, which provides an OpenAI-compatible API that makes tool calling seamless.\n",
    "\n",
    "## This notebook covers,\n",
    "- Introduction to Tool Calling\n",
    "- Using the Llama 3.1 8B Instruct model with the FuriosaAI SDK for tool calling\n",
    "- Building a simple search agent using LangChain tools and agents\n",
    "\n",
    "\n",
    "\n",
    "## Tool calling\n",
    "Tool calling extends an LLM's capabilities by allowing it to interact with external tools or functions. The available tools and their required input parameters are defined in the system prompt, and provided to the model along with the user's input. When the model receives a user query and determines that a tool is needed, it generates a tool call request in the JSON format. For example, if a user asks about the current weather in San Francisco, the model can issue a structured request to a weather API tool.\n",
    "\n",
    "When an LLM attempts to call a tool in response to a user query, it must extract the necessary parameters from the input and generate a structured output that conforms to the expected function call’s input format. This is a non-trivial task, as the model must not only accurately identify and format the required parameters according to the specific schema defined for the tool, but also generate the structured data for the tool calling request.\n",
    "\n",
    "To enable this capability, some approaches use few-shot prompting, where examples of tool usage and the required output format are provided as demonstrations. More recently, advanced models like Llama 3.1 8B have been trained with built-in tool-calling capabilities, allowing them to perform this process more reliably without extensive prompt engineering.\n",
    "\n",
    "You can follow the example steps below to test tool calling.\n",
    "\n",
    "#### 1. Define the tool\n",
    "```\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\", \"description\": \"City and state, e.g., 'San Francisco, CA'\"},\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "```\n",
    "\n",
    "#### 2. Receive the user’s input\n",
    "- \"What's the weather like in San Francisco?\"\n",
    "\n",
    "\n",
    "#### 3. Get the tool call request\n",
    "- Function called: `get_weather`\n",
    "- Arguments: {\"location\": \"San Francisco, CA\", \"unit\": \"fahrenheit\"}\n",
    "\n",
    "\n",
    "#### 4. Get tool call outputs by executing to python backend\n",
    "- Tool call outputs (by tool execution): \"Getting the weather for San Francisco, CA in fahrenheit...\"\n",
    "\n",
    "\n",
    "#### 5. Append the tool calling outputs and generate the final LLM responses\n",
    "- By appending the tool calling outputs to the previous chat history and calling the LLM, the model can generate the final outputs.\n",
    "- The final LLM response: \"The weather for San Francisco, CA is ...\" \n",
    "\n",
    "\n",
    "## How the FuriosaAI SDK supports tool calling\n",
    "The FuriosaAI SDK dramatically simplifies accelerated inference. It includes a powerful server that can run NPU-optimized models and expose them through an OpenAI-compatible REST API.\n",
    "For more extensive AI/ML inference workflows, the FuriosaAI SDK offers support for tool calling. This means that AI agents developed with FuriosaAI SDK are able to invoke external or custom tools while reasoning and generating responses. Let’s dive into how you can leverage tool calling with the FuriosaAI SDK to build an AI agent.\n",
    "\n",
    "## Prerequisites\n",
    "- Access to a RNGD servers\n",
    "- FuriosaSDK 2025.03\n",
    "- Install dependencies\n",
    "- Choose an AI application framework (we'll use Langchain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d021347",
   "metadata": {},
   "source": [
    "#### 1. Load RNGD servers\n",
    "\n",
    "- Load RNGD servers with `furiosa-llm serve` command.\n",
    "- We'll use tool calling supported server with `--enable-auto-tool-choice` and `--tool-call-parser`.\n",
    "\n",
    "\n",
    "```\n",
    "furiosa-llm serve furiosa-ai/Llama-3.1-8B-Instruct-FP8 \\\n",
    "    --enable-auto-tool-choice \\\n",
    "    --tool-call-parser llama3_json \\\n",
    "    --port 8000 \\\n",
    "    --devices \"npu:0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4989eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "port= 8000\n",
    "api_key=\"EMPTY\"\n",
    "client = OpenAI(base_url = f\"http://localhost:{port}/v1\", \n",
    "                api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4e595",
   "metadata": {},
   "source": [
    "## Chat with Tool calling \n",
    "Here are the four steps that simplify the process of LLM chat with tool calling:\n",
    "The model generates inputs for the tools.\n",
    "The specified tools are executed using these inputs, returning the corresponding outputs.\n",
    "The outputs from the tool calls are incorporated into the ongoing chat history.\n",
    "The model uses the tool outputs along with the prior context to generate the final response.\n",
    "\n",
    "#### 1. Tool Definition\n",
    "First, we need to specify the following arguments.\n",
    "name of tool\n",
    "description of tool\n",
    "json schema describing the inputs to the tool\n",
    "\n",
    "#### 2. Tool binding\n",
    "Once a tool is defined, the related information—such as tools and tool_choice—is passed into the chat API. By linking these tools with the language model, the model receives both the tools and the surrounding context. Based on the provided tool definitions and the selected tool_choice strategy, the model can generate a function call by deciding which tool to use and what input parameters to provide.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae985362",
   "metadata": {},
   "source": [
    "## Tool Usage -- Custom Tool Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af9f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def get_stock_price(ticker: str, currency: str) -> str:\n",
    "    price = round(random.uniform(100, 1500), 2)\n",
    "    return f\"The current price of {ticker.upper()} is {price} {currency.upper()}.\"\n",
    "\n",
    "def get_exchange_rate(base_currency: str, target_currency: str) -> str:\n",
    "    rate = round(random.uniform(0.5, 1.5), 4)\n",
    "    return f\"Current exchange rate from {base_currency.upper()} to {target_currency.upper()} is {rate}.\"\n",
    "\n",
    "def get_financial_news(company: str) -> str:\n",
    "    sample_news = [\n",
    "        f\"{company} reported better-than-expected quarterly earnings.\",\n",
    "        f\"{company} announced a strategic partnership to expand into new markets.\",\n",
    "        f\"Analysts are optimistic about {company}'s growth prospects for the upcoming year.\"\n",
    "    ]\n",
    "    return random.choice(sample_news)\n",
    "\n",
    "tool_functions = {\n",
    "    \"get_stock_price\": get_stock_price,\n",
    "    \"get_exchange_rate\": get_exchange_rate,\n",
    "    \"get_financial_news\": get_financial_news\n",
    "}\n",
    "\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_stock_price\",\n",
    "            \"description\": \"Retrieve the latest stock price for a given ticker symbol.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"ticker\": {\"type\": \"string\", \"description\": \"Stock ticker symbol, e.g., 'AAPL', 'TSLA'\"},\n",
    "                    \"currency\": {\"type\": \"string\", \"enum\": [\"USD\", \"EUR\", \"KRW\"], \"description\": \"Currency code for the price.\"}\n",
    "                },\n",
    "                \"required\": [\"ticker\", \"currency\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_exchange_rate\",\n",
    "            \"description\": \"Get the current exchange rate between two currencies.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"base_currency\": {\"type\": \"string\", \"description\": \"Base currency code, e.g., 'USD'\"},\n",
    "                    \"target_currency\": {\"type\": \"string\", \"description\": \"Target currency code, e.g., 'EUR'\"}\n",
    "                },\n",
    "                \"required\": [\"base_currency\", \"target_currency\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_financial_news\",\n",
    "            \"description\": \"Get recent financial news headlines related to a company.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"company\": {\"type\": \"string\", \"description\": \"Company name, e.g., 'Apple', 'Tesla'\"}\n",
    "                },\n",
    "                \"required\": [\"company\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "user_inputs = [\"What's Tesla's stock price in USD?\",\n",
    "              \"What's the current USD to EUR exchange rate?\",\n",
    "              \" Also, any recent news about Tesla?\"]\n",
    "\n",
    "\n",
    "tool_functions = {\"get_stock_price\": get_stock_price,\n",
    "                  \"get_exchange_rate\": get_exchange_rate,\n",
    "                  \"get_financial_news\": get_financial_news} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de2766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='chatcmpl-tool-1ce4b5b3ef324c8399b4151778f73021', function=Function(arguments='{\"ticker\": \"TSLA\", \"currency\": \"USD\"}', name='get_stock_price'), type='function')], reasoning_content=None))\n",
      "Function called: get_stock_price\n",
      "Arguments: {\"ticker\": \"TSLA\", \"currency\": \"USD\"}\n",
      "Result: The current price of TSLA is 1363.53 USD.\n",
      "===================\n",
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='chatcmpl-tool-fcf9999bf2cd4e8bb020b5f8bd0c0927', function=Function(arguments='{\"base_currency\": \"USD\", \"target_currency\": \"EUR\"}', name='get_exchange_rate'), type='function')], reasoning_content=None))\n",
      "Function called: get_exchange_rate\n",
      "Arguments: {\"base_currency\": \"USD\", \"target_currency\": \"EUR\"}\n",
      "Result: Current exchange rate from USD to EUR is 1.4235.\n",
      "===================\n",
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='chatcmpl-tool-1a8d07de1c1b479c957fac36ba749171', function=Function(arguments='{\"company\": \"Tesla\"}', name='get_financial_news'), type='function')], reasoning_content=None))\n",
      "Function called: get_financial_news\n",
      "Arguments: {\"company\": \"Tesla\"}\n",
      "Result: Analysts are optimistic about Tesla's growth prospects for the upcoming year.\n"
     ]
    }
   ],
   "source": [
    "for user_input in user_inputs:\n",
    "    messages = [{\"role\": \"user\", \"content\": user_input}]\n",
    " \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"furiosa-ai/Llama-3.1-8B-Instruct-FP8\",\n",
    "        messages=messages,\n",
    "        tools=custom_tools,\n",
    "        tool_choice=\"auto\",\n",
    "        max_completion_tokens=100,\n",
    "    )\n",
    "\n",
    "    print(\"===================\")\n",
    "    print(response.choices[0])\n",
    "    tool_call = response.choices[0].message.tool_calls[0].function\n",
    "    print(f\"Function called: {tool_call.name}\")\n",
    "    print(f\"Arguments: {tool_call.arguments}\")\n",
    "    print(f\"Result: {tool_functions[tool_call.name](**json.loads(tool_call.arguments))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
